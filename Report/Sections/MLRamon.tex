\subsection{Associate the Twitter Data}
\textbf{Name:} Ramon de Vaan \indent \textbf{StudentNumber:} 0758873

\subsubsection*{Motivation}
Now that we have both a set of Tweets, and a set of P2000 notifications, we want to associate the two.
Preferably, we want a number of tweets per P2000 notification, in a ranking.
In that way, when the user will inspect a certain P2000 notification, he will be able to gather additional information from the related tweets.

\subsubsection*{Approach}
We have devised a Java program that grabs all twitter messages and all notifications from the server, and writes the associations between them back to the server using the JDBC library.
However, we want to associate on a cluster level, instead of on a notification level.
Therefore, some preprocessing is required before the association analysis. \\
Notifications are assigned the lowest notification id of the notifications in its cluster.
However, notifications not belonging to a cluster may be given cluster id \textsc{NULL}.
Additionally, it might occur that the head of a cluster is given cluster id \textsc{NULL}. \\
To solve this, first of all we assign every notification that has \textsc{NULL} as a cluster id, its own notification id as cluster id.
We can then sort the notifications by cluster id, and merge notifications with the same cluster id. \\

To compute the measure of association, we use the \textit{tf.idf} algorithm described in class.
In this case, the clusters are to serve as queries, and the twitter messages serve as documents.
Now that we have clusters, we need to turn the set of notifications into a query.
We do this by merging the text of each of the notifications, and removing duplicate terms.
Additionally, the cluster is given the set of notification types appearing in its notifications. \\
The twitter data is preprocessed as well. 
We compute the set of terms that appear in them, compute the term frequency per message, and the document frequency per term. \\

With the data preprocessed, we're ready to start computing the score.
However, we have one added requirement.
We do not want Twitter data that is in no way related to a cluster to be assigned a score for that cluster. \\
A twitter message may score very high based on the same terms occurring in both a cluster a tweet, but as we discussed earlier, P2000 notifications are not very well defined.
As such, a P2000 notification that has the word ambulance in it, may be associated to twitter messages on the other side of the country, also saying ambulance.
We want to ensure that only twitter messages that have a chance of being related are considered. \\

To solve this, we grab a subset of twitter messages from the document collection by comparing metadata.
Twitter messages are often assigned a location from where they were tweeted.
P2000 messages are assigned both a town and a region.
As such, a twitter message is only selected if its message contains the town or region from a P2000 notification, or if its location is equal to one of those. \\
Additionally, twitter messages have been assigned a label by the classification algorithm.
A twitter message won't be considered if the label is not related to the notification type of the notification. \\
Lastly, we only consider twitter messages that are posted after the earliest notification in a cluster.
We assume that P2000 notifications occur before related twitter messages, as people would be more inclined to call emergency services in the event of an accident, than to post about it on Twitter.
As a result, any messages that occur before a notification are assumed to be related to another notification. \\

For every message that remains after the filtering, the score is calculated, and written to the database.

\subsubsection*{Evaluation}
The program successfully produces a set of association entries in the database.
Each of these is given a score corresponding to what extent the twitter message associates to the P2000 cluster.
However, as of now, it is not much of a machine learning task.
There is no evaluation in the sense that we learn from what associations we produced in the past, to influence associations in the future, it has become more of an extended IR task.
It is rather difficult to do so using the means we were taught in class. \\
If we had a large userbase for our program, we could attempt to measure how many times each tweet was clicked in relation to a cluster of P2000 notifications, and let that affect the score.
In that way, when another user inspects the same cluster, the system will have learned from previous users.
But the use of this is debatable, for one, users will probably be interested in the latest data for a given location, so the number of clicks may not have influenced the ranking as much. \\

One could argue that there is still some amount of machine learning through the use of P2000 and Twitter labels by the program.
These do alter the association results, as the labels have to match for a tweet to be considered as associated.
As the labelling algorithms mature, the set of associated tweets will probably return better results as well. \\
Additionally, the clustering of the P2000 notifications will alter the results.
Good clusters will produce better association results, while clusters that have unrelated P2000 notifications may return a multitude of twitter message that are not necessarily related to each P2000 notification in a cluster. \\

Another issue is the fact that the program does not run on the server, instead running on a local computer.
It would be better to re-run the program every time a new set of P2000 notifications and Twitter messages are collected, after the clustering and classification steps.
The current program simply grabs all notifications and all twitter messages and tries to associate them. 
Obviously, as the set of notifications and twitter messages grow, this will eventually become to expensive in terms of bandwidth usage, and computational power.
However, the program can easily be adapted to run on subsets, and on the server.
The server would have to be adapted to keep track of the set of terms, and the document frequency of each term.
For the duration of this course, the current implementation suffices.