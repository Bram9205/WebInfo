\subsection{Indexing of news feed / twitter data   }
\textbf{Name:} Bart van Wezel  \textbf{StudentNumber:} 0740608

\subsubsection*{Motivation}
The indexing should happen after the Language detection \& spell check is applied. This way we know that the input data is mostly correct.  The collected data should be stored in a efficient way, such that queries can be executed on the data. This should be done in an efficient way, which can be done with indexing the collected data. 
For example we know that a lot of queries will want to look for the location and the date. 
We will probably also use the whole text for classying the news or tweet. 

\subsubsection*{Approach}
We used a plugin to index the text, because this way we could execute fast search queries on full text. 
TEKST OVER ELASTIC SEARCH EN WAAROM HET SUPER MEGA COOL IS EN LINK NAAR APPENDIX WOEHOOEE \\
Before we index the text from the news page or tweet, we first apply the tokonizer on the text.
However to tokonize the text, we have to find the correct text, that needs to be tokonized.
Since the tweets use a default format, we can easily get this text from the tweet. 
However the news page are all in HTML format and not every news site uses the same format. 
So to parse those HTML files, we had to apply some different rules for different news sites.
Luckily each news site had some formatting done on the pages, so we could take the text of a CSS part of the page. 
We defined this part for each of the news site, so we could import the text of those news pages.  \\
We also search for the location in the news pages. 
Since most news pages write the name of the city before the article, we decided to use this location.
There were some minor problems with looking for cities that consists of multiple words. 
At first we only compared the first word, however `DEN' is not a city and `DEN HAAG' is. 
We solved this problem by comparing both the first word as the first two words with every city name in the Netherlands. \\
 For the tweets we take the location of the tweet if present. 
If the tweet has no location, the location of the user is used. 
This is ussualy the home town of the user and not the location from which the tweet was send.\\ 

\subsubsection*{Evaluation $\&$ Possible Improvements }
TODO EVALUATION
Improvements could be made in the indexing. Now some tweets and news pages failed to be inserted into the tokonizer, because of an unusual text format. 
This could be increased by converting the format, before applying the tokonizer. 
However this were only a few cases in which the text format was really different, so we did not focus on those cases yet. \\
Another improvement could be a more advanced location finder. 
Now we assume that news page write their location at the start of the article and compare it to a list of Dutch cities.
However not all news articles have such an location and some locations are not real cities, but a popular area. 
We could improve the indexing in such a way that it searches for a location inside the text. This was still pretty hard, because some Dutch cities have the same name as words that are also used in texts. For example EEN and MEER are Dutch words that are used a lot, but they are also cities. \\
Another improvement could be to look for the time of the news article. The time can be found on the page or in the text. 
For example we could find `Saturday morning', then we know it happend between 6.00 and 12.00 am. 
Another search could be to the time the article is published. 
However this gives problems with updates of the article and multiple times on the news page. 
Perhaps this could be done, by making an unique learner for each different news site. 